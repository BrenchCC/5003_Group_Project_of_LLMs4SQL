{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "296efe73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nested_Join',\n",
       " 'Condition_EXISTs',\n",
       " 'Reorder_Conditions ',\n",
       " 'CTEs',\n",
       " 'Swapping_Nestedness',\n",
       " 'Join_Nested',\n",
       " 'Condition_Nested',\n",
       " 'Simplification',\n",
       " 'Explicit_Implicit_Joins',\n",
       " 'Join_Order',\n",
       " 'Condition_IntersectUnion',\n",
       " 'Operators',\n",
       " 'Logical_Conditions',\n",
       " 'Case_Statement',\n",
       " 'Using Explicit JOINs',\n",
       " 'Change_Alias']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"raw_data/Tasks/equi_join.csv\")\n",
    "value_dict = df[df[\"Original\"]==\"YES\"][\"Modification_Method\"].value_counts().to_dict()\n",
    "keys1 = [key for key in value_dict.keys()]\n",
    "\n",
    "df = pd.read_csv(\"raw_data/Tasks/equi_sdss.csv\")\n",
    "value_dict = df[df[\"Original\"]==\"YES\"][\"Modification_Method\"].value_counts().to_dict()\n",
    "keys2 = [key for key in value_dict.keys()]\n",
    "\n",
    "df = pd.read_csv(\"raw_data/Tasks/equi_sqlshare.csv\")\n",
    "value_dict = df[df[\"Original\"]==\"YES\"][\"Modification_Method\"].value_counts().to_dict()\n",
    "keys3 = [key for key in value_dict.keys()]\n",
    "\n",
    "total_keys = list(set(keys1 + keys2 + keys3))\n",
    "total_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "666e80e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e74bde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Change_Join_Condition',\n",
       " 'Group_by_Criteria',\n",
       " 'Adding_Removing_Select_Column',\n",
       " 'Value_Change',\n",
       " 'Change_Sorting_Limiting',\n",
       " 'Aggregate_Function',\n",
       " 'Operators',\n",
       " 'Logical_Conditions',\n",
       " 'Change_Table',\n",
       " 'Order_by_Column',\n",
       " 'Change_Data_Type',\n",
       " 'Change_Alias']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "value_dict = df[df[\"Original\"]==\"NO\"][\"Modification_Method\"].value_counts().to_dict()\n",
    "keys1 = [key for key in value_dict.keys()]\n",
    "\n",
    "value_dict = df[df[\"Original\"]==\"NO\"][\"Modification_Method\"].value_counts().to_dict()\n",
    "keys2 = [key for key in value_dict.keys()]\n",
    "\n",
    "value_dict = df[df[\"Original\"]==\"NO\"][\"Modification_Method\"].value_counts().to_dict()\n",
    "keys3 = [key for key in value_dict.keys()]\n",
    "\n",
    "total_negative_keys = list(set(keys1 + keys2 + keys3))\n",
    "total_negative_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09eaaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_negative_keys)"
   ]
  },
  {
   "cell_type": "code",
   "id": "91bdfc0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T18:50:40.026785Z",
     "start_time": "2025-12-05T18:50:40.021168Z"
    }
   },
   "source": [
    "mapping_positive_dict = {\n",
    "    'Condition_EXISTs': 'Subquery_Conditions',\n",
    "    'Case_Statement': 'Case_Statement',\n",
    "    'Simplification': 'Query_Simplification',\n",
    "    'Explicit_Implicit_Joins': 'Join_Style',\n",
    "    'Operators': 'Operators',\n",
    "    'Reorder_Conditions': 'Condition_Arrangement',  # 注意：原始术语中的尾随空格已去除，以便一致性\n",
    "    'Change_Alias': 'Alias_Change',\n",
    "    'Using Explicit JOINs': 'Join_Style',\n",
    "    'Condition_IntersectUnion': 'Set_Operations',\n",
    "    'CTEs': 'CTEs',\n",
    "    'Join_Order': 'Join_Structure',\n",
    "    'Join_Nested': 'Join_Structure',\n",
    "    'Nested_Join': 'Join_Structure',\n",
    "    'Swapping_Nestedness': 'Join_Structure',\n",
    "    'Condition_Nested': 'Subquery_Conditions',\n",
    "    'Logical_Conditions': 'Condition_Arrangement'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Subquery_Conditions：涵盖子查询相关的条件变换，包括存在性条件（EXISTS）和嵌套条件。\n",
    "Case_Statement：专门处理CASE语句的使用和变换。\n",
    "Query_Simplification：涉及查询的简化操作，如去除冗余条件或结构。\n",
    "Join_Style：合并了显式JOIN与隐式JOIN（逗号连接）的风格变换。\n",
    "Operators：保留操作符相关的变换，如比较操作符的改变。\n",
    "Condition_Arrangement：涵盖条件的重新排列和逻辑条件的修改。\n",
    "Alias_Change：专门处理表或列别名的改变。\n",
    "Set_Operations：涉及集合操作（如INTERSECT、UNION）的使用。\n",
    "CTEs：专门处理公共表表达式（CTE）的使用和变换。\n",
    "Join_Structure：合并了连接结构的多种变换，包括连接顺序、嵌套连接和嵌套度交换。\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSubquery_Conditions：涵盖子查询相关的条件变换，包括存在性条件（EXISTS）和嵌套条件。\\nCase_Statement：专门处理CASE语句的使用和变换。\\nQuery_Simplification：涉及查询的简化操作，如去除冗余条件或结构。\\nJoin_Style：合并了显式JOIN与隐式JOIN（逗号连接）的风格变换。\\nOperators：保留操作符相关的变换，如比较操作符的改变。\\nCondition_Arrangement：涵盖条件的重新排列和逻辑条件的修改。\\nAlias_Change：专门处理表或列别名的改变。\\nSet_Operations：涉及集合操作（如INTERSECT、UNION）的使用。\\nCTEs：专门处理公共表表达式（CTE）的使用和变换。\\nJoin_Structure：合并了连接结构的多种变换，包括连接顺序、嵌套连接和嵌套度交换。\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a927f8c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T18:50:43.599716Z",
     "start_time": "2025-12-05T18:50:43.595792Z"
    }
   },
   "source": [
    "mapping_negative_dict = {\n",
    "    'Adding_Removing_Select_Column': 'Select_Clause_Modification',\n",
    "    'Change_Data_Type': 'Data_Type_Change',\n",
    "    'Operators': 'Operator_Change',\n",
    "    'Aggregate_Function': 'Aggregate_GroupBy_Change',\n",
    "    'Operator': 'Operator_Change',  # 合并到Operator_Change\n",
    "    'Change_Alias': 'Select_Clause_Modification',\n",
    "    'Order_by_Column': 'Sorting_Limiting_Change',\n",
    "    'Change_Sorting_Limiting': 'Sorting_Limiting_Change',\n",
    "    'Remove_Condition': 'Condition_Modification',\n",
    "    'Group_by_Criteria': 'Aggregate_GroupBy_Change',\n",
    "    'Use Aggregate_Function': 'Aggregate_GroupBy_Change',  # 合并到Aggregate_GroupBy_Change\n",
    "    'Add_Remove_Distinct': 'Select_Clause_Modification',\n",
    "    'Change_Table': 'Table_Join_Modification',\n",
    "    'Change_Join_Condition': 'Table_Join_Modification',\n",
    "    'Logical_Conditions': 'Condition_Modification',\n",
    "    'Value_Change': 'Value_Change'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "映射说明：\n",
    "Select_Clause_Modification：涵盖选择子句的修改，包括添加/移除列、改变别名、添加/移除DISTINCT等。\n",
    "Data_Type_Change：专门处理数据类型的改变。\n",
    "Operator_Change：合并了操作符相关的变换（如比较操作符、逻辑操作符）。\n",
    "Aggregate_GroupBy_Change：合并了聚合函数和GROUP BY子句的修改。\n",
    "Sorting_Limiting_Change：涵盖排序（ORDER BY）和限制（LIMIT）子句的修改。\n",
    "Condition_Modification：涵盖WHERE条件子句的修改，包括移除条件、改变逻辑条件等。\n",
    "Table_Join_Modification：涵盖表和连接条件的修改，如改变表名、连接条件等。\n",
    "Value_Change：专门处理查询中字面值的改变。\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n映射说明：\\nSelect_Clause_Modification：涵盖选择子句的修改，包括添加/移除列、改变别名、添加/移除DISTINCT等。\\nData_Type_Change：专门处理数据类型的改变。\\nOperator_Change：合并了操作符相关的变换（如比较操作符、逻辑操作符）。\\nAggregate_GroupBy_Change：合并了聚合函数和GROUP BY子句的修改。\\nSorting_Limiting_Change：涵盖排序（ORDER BY）和限制（LIMIT）子句的修改。\\nCondition_Modification：涵盖WHERE条件子句的修改，包括移除条件、改变逻辑条件等。\\nTable_Join_Modification：涵盖表和连接条件的修改，如改变表名、连接条件等。\\nValue_Change：专门处理查询中字面值的改变。\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T18:53:39.270691Z",
     "start_time": "2025-12-05T18:53:39.268122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l1 = [key for key in mapping_negative_dict.keys()]\n",
    "l1.extend([key for key in mapping_positive_dict.keys()])\n",
    "print(len(l1))\n",
    "s1 = set(l1)\n",
    "len(s1)"
   ],
   "id": "5d49945b3bd9a078",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T18:58:37.539704Z",
     "start_time": "2025-12-05T18:58:36.912238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def map_modification_method(positive_mapping, negative_mapping, csv_path):\n",
    "    \"\"\"\n",
    "    对CSV文件中的\"Modification_Method\"列进行映射\n",
    "\n",
    "    参数:\n",
    "    - positive_mapping: dict, 当Original==\"YES\"时使用的映射表\n",
    "    - negative_mapping: dict, 当Original==\"NO\"时使用的映射表\n",
    "    - csv_path: str, CSV文件路径\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 读取CSV文件\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # 2. 处理每一行的映射\n",
    "    mapped_values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        original_value = row.get(\"Original\", \"\")\n",
    "        mod_method = str(row.get(\"Modification_Method\", \"\")).strip()\n",
    "\n",
    "        # 根据Original的值选择映射表\n",
    "        if original_value == \"YES\":\n",
    "            mapping_table = positive_mapping\n",
    "        elif original_value == \"NO\":\n",
    "            mapping_table = negative_mapping\n",
    "        else:\n",
    "            # 如果Original不是YES或NO，保持原值\n",
    "            mapped_values.append(mod_method)\n",
    "            continue\n",
    "\n",
    "        # 进行映射，如果找不到映射则保持原值\n",
    "        mapped_value = mapping_table.get(mod_method, mod_method)\n",
    "        mapped_values.append(mapped_value)\n",
    "\n",
    "    # 3. 将映射后的值赋回DataFrame\n",
    "    df[\"Modification_Method\"] = mapped_values\n",
    "\n",
    "    # 4. 生成新文件名（在原文件名后添加_mapping）\n",
    "    dir_name = os.path.dirname(csv_path)\n",
    "    file_name = os.path.basename(csv_path)\n",
    "    name_without_ext, ext = os.path.splitext(file_name)\n",
    "    new_file_name = f\"{name_without_ext}_mapping{ext}\"\n",
    "    new_file_path = os.path.join(dir_name, new_file_name)\n",
    "\n",
    "    # 5. 保存到新文件\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "\n",
    "    print(f\"映射完成！文件已保存到: {new_file_path}\")\n",
    "    return df, new_file_path"
   ],
   "id": "6fa02a063860368e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T18:58:38.084051Z",
     "start_time": "2025-12-05T18:58:38.068974Z"
    }
   },
   "cell_type": "code",
   "source": "map_modification_method(mapping_positive_dict, mapping_negative_dict, \"processed_data/equi_join.csv\")",
   "id": "c5370c896d0b7461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "映射完成！文件已保存到: processed_data/equi_join_mapping.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                         SQL_Statement  \\\n",
       " 0    SELECT MIN(chn.name) AS uncredited_voiced_char...   \n",
       " 1    SELECT MIN(chn.name) AS character,\\n       MIN...   \n",
       " 2    SELECT MIN(chn.name) AS character,\\n       MIN...   \n",
       " 3    SELECT MIN(cn.name) AS from_company,\\n       M...   \n",
       " 4    SELECT MIN(cn.name) AS from_company,\\n       M...   \n",
       " ..                                                 ...   \n",
       " 145  SELECT MIN(an.name) AS cool_actor_pseudonym,\\n...   \n",
       " 146  SELECT MIN(an.name) AS cool_actor_pseudonym,\\n...   \n",
       " 147  SELECT MIN(n.name) AS member_in_charnamed_amer...   \n",
       " 148  SELECT MIN(n.name) AS member_in_charnamed_movi...   \n",
       " 149  SELECT MIN(lt.link) AS link_type,\\n       MIN(...   \n",
       " \n",
       "                                     Equivalent_Queries Equivalent or not  \\\n",
       " 0    SELECT MIN(chn.name) AS uncredited_voiced_char...        Equivalent   \n",
       " 1    WITH FilteredMovies AS (\\n    SELECT \\n       ...        Equivalent   \n",
       " 2    SELECT MIN(chn.name) AS character,\\n       MIN...    Not Equivalent   \n",
       " 3    SELECT MIN(cn.name) AS from_company,\\n       M...        Equivalent   \n",
       " 4    SELECT MIN(cn.name) AS from_company,\\n       M...    Not Equivalent   \n",
       " ..                                                 ...               ...   \n",
       " 145  WITH FilteredTitles AS (\\n    SELECT t.id AS m...        Equivalent   \n",
       " 146  SELECT MIN(an.name) AS cool_actor_pseudonym,\\n...    Not Equivalent   \n",
       " 147  SELECT MIN(n.name) AS member_in_charnamed_amer...        Equivalent   \n",
       " 148  SELECT MIN(n.name) AS member_in_charnamed_movi...        Equivalent   \n",
       " 149  SELECT MIN(lt.link) AS link_type,\\n       MIN(...    Not Equivalent   \n",
       " \n",
       "           Modification_Method Original  \n",
       " 0                  Join_Style      YES  \n",
       " 1                        CTEs      YES  \n",
       " 2             Operator_Change       NO  \n",
       " 3                  Join_Style      YES  \n",
       " 4    Aggregate_GroupBy_Change       NO  \n",
       " ..                        ...      ...  \n",
       " 145                      CTEs      YES  \n",
       " 146              Value_Change       NO  \n",
       " 147       Subquery_Conditions      YES  \n",
       " 148            Case_Statement      YES  \n",
       " 149              Value_Change       NO  \n",
       " \n",
       " [150 rows x 5 columns],\n",
       " 'processed_data/equi_join_mapping.csv')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:00:09.572037Z",
     "start_time": "2025-12-05T19:00:09.556133Z"
    }
   },
   "cell_type": "code",
   "source": "map_modification_method(mapping_positive_dict, mapping_negative_dict, \"processed_data/equi_sdss.csv\")",
   "id": "40eacfd44974b279",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "映射完成！文件已保存到: processed_data/equi_sdss_mapping.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                         SQL_Statement  \\\n",
       " 0    SELECT DISTINCT s.run2d, s.plate, s.mjd, s.fib...   \n",
       " 1    SELECT TOP 1_x000D_\\n s.instrument, s.bossSpec...   \n",
       " 2     SELECT TOP 10 * FROM Star WHERE ra >= 60 AND ...   \n",
       " 3    select top 1 objid, z, zerr, photoerrorclass f...   \n",
       " 4    SELECT\\n    DB_NAME() AS [database_name],\\n   ...   \n",
       " ..                                                 ...   \n",
       " 245  \\nSELECT COUNT(g.objID) AS galaxy_count\\nFROM ...   \n",
       " 246  \\nSELECT AVG(q.z) AS avg_redshift\\nFROM SpecOb...   \n",
       " 247  \\nSELECT COUNT(s1.objID) AS star_count\\nFROM S...   \n",
       " 248  \\nSELECT SUM(g.petromag_r) AS total_magnitude\\...   \n",
       " 249  \\nSELECT SUM(g.petromag_r) AS total_magnitude\\...   \n",
       " \n",
       "                                     Equivalent_Queries Equivalent or not  \\\n",
       " 0    SELECT DISTINCT s.run2d, s.plate, s.mjd, s.fib...        Equivalent   \n",
       " 1    SELECT TOP 1\\n  s.instrument, s.bossSpecObjID,...        Equivalent   \n",
       " 2    WITH FilteredStar AS (\\nSELECT TOP 10 * FROM S...        Equivalent   \n",
       " 3    WITH CTE_PhotoZ AS (\\n    SELECT objid, z, zer...        Equivalent   \n",
       " 4    SELECT\\n    DB_NAME() AS [database_name],\\n   ...    Not Equivalent   \n",
       " ..                                                 ...               ...   \n",
       " 245  SELECT COUNT(g.objID) AS galaxy_count\\nFROM Ga...        Equivalent   \n",
       " 246  SELECT AVG(q.z) AS avg_redshift\\nFROM SpecObj ...        Equivalent   \n",
       " 247  SELECT COUNT(s1.objID) AS star_count\\nFROM Spe...        Equivalent   \n",
       " 248  \\nSELECT SUM(g.petromag_r) AS total_magnitude\\...    Not Equivalent   \n",
       " 249  SELECT SUM(g.petromag_r) AS total_magnitude\\nF...        Equivalent   \n",
       " \n",
       "             Modification_Method Original  \n",
       " 0                Join_Structure      YES  \n",
       " 1                    Join_Style      YES  \n",
       " 2                          CTEs      YES  \n",
       " 3                          CTEs      YES  \n",
       " 4      Aggregate_GroupBy_Change       NO  \n",
       " ..                          ...      ...  \n",
       " 245              Join_Structure      YES  \n",
       " 246              Join_Structure      YES  \n",
       " 247              Join_Structure      YES  \n",
       " 248  Select_Clause_Modification       NO  \n",
       " 249              Join_Structure      YES  \n",
       " \n",
       " [250 rows x 5 columns],\n",
       " 'processed_data/equi_sdss_mapping.csv')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:00:28.804949Z",
     "start_time": "2025-12-05T19:00:28.785763Z"
    }
   },
   "cell_type": "code",
   "source": "map_modification_method(mapping_positive_dict, mapping_negative_dict, \"processed_data/equi_sqlshare.csv\")",
   "id": "a4dcff527f595f86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "映射完成！文件已保存到: processed_data/equi_sqlshare_mapping.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                         SQL_Statement  \\\n",
       " 0    SELECT  SUM(cnt) FROM ( SELECT  z, COUNT(DISTI...   \n",
       " 1    WITH  pop AS (SELECT  [time],  [pop],  log([fs...   \n",
       " 2    SELECT  * max(salary),  min(salary),  avg(sala...   \n",
       " 3    SELECT  ROW_NUMBER() OVER (PARTITION BY TAIL_N...   \n",
       " 4    SELECT max(salary),  min(salary),  avg(salary)...   \n",
       " ..                                                 ...   \n",
       " 245  SELECT  T1 ,  C1 ,  S ,  SV ,  T2 ,  case when...   \n",
       " 246  WITH  DEGMIN (DLAT,  DLON) AS (SELECT  CAST([L...   \n",
       " 247  SELECT TOP 5 *, COUNT(*) OVER () AS TotalCount...   \n",
       " 248  select ecp.pathway_name,  se.genus,  count(ecp...   \n",
       " 249  SELECT  Distinct SightDate,  Month,  Day,  [Ye...   \n",
       " \n",
       "                                     Equivalent_Queries Equivalent or not  \\\n",
       " 0    SELECT SUM(COUNT(DISTINCT a.follower)) AS Tota...        Equivalent   \n",
       " 1    SELECT *\\nFROM (\\n    SELECT [time], [pop], lo...        Equivalent   \n",
       " 2    SELECT MAX(CASE WHEN job_title LIKE '%RESEAR%S...        Equivalent   \n",
       " 3    SELECT ROW_NUMBER() OVER (PARTITION BY TAIL_NU...        Equivalent   \n",
       " 4    SELECT \\n    MAX([2010 Gross Earnings]) AS max...        Equivalent   \n",
       " ..                                                 ...               ...   \n",
       " 245  SELECT  T1 ,  C1 ,  S ,  SV ,  T2 ,T3  case wh...    Not Equivalent   \n",
       " 246  SELECT TOP 5\\n    ROUND(CAST([LAT] AS FLOAT)/1...        Equivalent   \n",
       " 247  WITH FilteredData AS (\\n    SELECT *\\n    FROM...        Equivalent   \n",
       " 248  select ecp.pathway_name,  se.genus,  count(ecp...    Not Equivalent   \n",
       " 249  SELECT DISTINCT SightDate, Month, Day, [Year]\\...        Equivalent   \n",
       " \n",
       "             Modification_Method Original  \n",
       " 0                Join_Structure      YES  \n",
       " 1           Subquery_Conditions      YES  \n",
       " 2                Case_Statement      YES  \n",
       " 3           Subquery_Conditions      YES  \n",
       " 4          Query_Simplification      YES  \n",
       " ..                          ...      ...  \n",
       " 245  Select_Clause_Modification       NO  \n",
       " 246        Query_Simplification      YES  \n",
       " 247                        CTEs      YES  \n",
       " 248     Table_Join_Modification       NO  \n",
       " 249         Subquery_Conditions      YES  \n",
       " \n",
       " [250 rows x 5 columns],\n",
       " 'processed_data/equi_sqlshare_mapping.csv')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2be336b6e4599feb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms4sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
